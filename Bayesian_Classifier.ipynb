{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian classifier  for Credit Card Default Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO ?\n",
    "# check the correlation between variables and if it is possible to reduce the dimensionality ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## IMPORTING LIBRARIES  ##\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "## IMPORTING DATASET ##\n",
    "## source: https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset/data ##\n",
    "default_credit_card_dataset=np.genfromtxt('UCI_Credit_Card.csv',delimiter=',')\n",
    "\n",
    "# Remove the first line of the data set, which only contain the column names\n",
    "dataset = default_credit_card_dataset[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WARMING UP (will not be in the final delivery of the project)  ##\n",
    "## TRYING TO REPRODUCE MAHYAR'S VISUAL EXPLORATORY DATA ANALYSIS USING NUMPY INSTEAD OF PANDAS ##\n",
    "\n",
    "# Select rows where last column (default_payment_next_month) is greater than 0 and only keep the first column (LIMIT_BAL)\n",
    "# print dataset[dataset[:,-1] > 0][:,1]\n",
    "\n",
    "bins = 30\n",
    "pyplot.hist(dataset[:,1], bins = bins, color='m',label = 'Total',alpha=0.5)\n",
    "pyplot.hist(dataset[dataset[:,-1] > 0][:,1], bins = bins, color='b',label = 'Default')\n",
    "pyplot.xlabel('Credit Limit (NT dollar)')\n",
    "pyplot.ylabel('Number of Accounts')\n",
    "pyplot.title('Fig.1 : Credit Limit ',fontweight=\"bold\", size=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gauss_density_estimator:\n",
    "    def __init__(self,n_dims):\n",
    "        self.mu = np.zeros((1,n_dims))\n",
    "        self.n_dims = n_dims\n",
    "        self.sigma_sq = np.ones(n_dims)\n",
    "        \n",
    "    def train(self, train_data):\n",
    "        self.mu = np.mean(train_data, axis = 0)\n",
    "        self.sigma_sq =  np.sum((train_data - self.mu) ** 2.0, axis = 0) / train_data.shape[0]\n",
    "        \n",
    "    def compute_predictions(self, test_data):\n",
    "        c = -self.n_dims * np.log(2*np.pi)/2.0 - np.log(np.prod(self.sigma_sq))/2.0\n",
    "        log_prob = c - np.sum((test_data -  self.mu)**2.0/ (2.0 * self.sigma_sq),axis=1)\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class classif_bayes:\n",
    "\n",
    "    def __init__(self,modeles_mv, priors):\n",
    "        self.modeles_mv = modeles_mv\n",
    "        self.priors = priors\n",
    "        if len(self.modeles_mv) != len(self.priors):\n",
    "            print 'Le nombre de modeles MV doit etre egale au nombre de priors!'\n",
    "        \n",
    "        self.n_classes = len(self.modeles_mv)\n",
    "                                                            \n",
    "    # Retourne une matrice de taille nb. ex. de test x nombre de classes contenant les log\n",
    "    # probabilitÃ©s de chaque exemple de test sous chaque modÃ¨le MV. \n",
    "    def compute_predictions(self, test_data, eval_by_group=False):\n",
    "        log_pred = np.empty((test_data.shape[0],self.n_classes))\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            # ici il va falloir utiliser modeles_mv[i] et priors pour remplir\n",
    "            # chaque colonne de log_pred (c'est plus efficace de faire tout une\n",
    "            # colonne a la fois)\n",
    "            \n",
    "            log_pred[:,i] = self.modeles_mv[i].compute_predictions(test_data) +  np.log(self.priors[i])\n",
    "\n",
    "        return log_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CREATING TEST AND TRAINING GROUPS ##\n",
    "# 1- separate the two classes\n",
    "dataset_default_payment_records = dataset[dataset[:,-1] > 0]\n",
    "dataset_nodefault_payment_records = dataset[dataset[:,-1] < 1]\n",
    "\n",
    "# 2- remove the last column (which is the label)\n",
    "# dataset_default_payment_records = np.delete(dataset_default_payment_records, -1, axis=1)\n",
    "# dataset_nodefault_payment_records = np.delete(dataset_nodefault_payment_records, -1, axis=1)\n",
    "\n",
    "# 2- shuffle each class dataset\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(dataset_default_payment_records)\n",
    "np.random.shuffle(dataset_nodefault_payment_records)\n",
    "\n",
    "# 3- divide each class in 60-40 proportion (for training and testing purposes)\n",
    "default_dataset_number_of_records = len(dataset_default_payment_records)\n",
    "nodefault_dataset_number_of_records = len(dataset_nodefault_payment_records)\n",
    "\n",
    "split_index_default = int(default_dataset_number_of_records * 0.6)\n",
    "split_index_nodefault = int(nodefault_dataset_number_of_records * 0.6)\n",
    "\n",
    "dataset_default_for_training = dataset_default_payment_records[:split_index_default]\n",
    "dataset_default_for_testing = dataset_default_payment_records[split_index_default:]\n",
    "\n",
    "dataset_nodefault_for_training = dataset_nodefault_payment_records[:split_index_nodefault]\n",
    "dataset_nodefault_for_testing = dataset_nodefault_payment_records[split_index_nodefault:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TRAINING THE DIAGONAL GAUSSIAN MODELS ##\n",
    "\n",
    "# Reminder : shape return a tuple (number of rows, number of columns)\n",
    "# minus 2 because the first column (ID) and the last (labels) are irrelevants when training\n",
    "number_of_dimensions = dataset_default_for_training.shape[1] - 2\n",
    "\n",
    "# Initializing Gaussian kernel\n",
    "default_payment_diagonal_gaussian_model = gauss_density_estimator(number_of_dimensions)\n",
    "nodefault_payment_diagonal_gaussian_model = gauss_density_estimator(number_of_dimensions)\n",
    "\n",
    "# Training - we don't keep the first and the last column (respectively ID and labels) for the training\n",
    "default_payment_diagonal_gaussian_model.train(dataset_default_for_training[:,1:-1])\n",
    "nodefault_payment_diagonal_gaussian_model.train(dataset_nodefault_for_training[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## BAYES CLASSIFIER INITIALIZATION ##\n",
    "\n",
    "# 1- Calculating priors for each class\n",
    "total_number_of_records = dataset.shape[0]\n",
    "# if there the division is made only by int numbers, the result will be 0\n",
    "# need to convert at least one int to float to avoid that\n",
    "total_number_of_records = float(total_number_of_records)\n",
    "\n",
    "priors_nodefault_payment = nodefault_dataset_number_of_records / total_number_of_records\n",
    "priors_default_payment = default_dataset_number_of_records / total_number_of_records\n",
    "\n",
    "# 2- Initializing bayes classifier\n",
    "models_array = [default_payment_diagonal_gaussian_model, nodefault_payment_diagonal_gaussian_model]\n",
    "priors_array = [priors_default_payment, priors_nodefault_payment]\n",
    "default_payment_bayes_classifier = classif_bayes(models_array, priors_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate (training) 84.24%\n",
      "Error Rate (test) 84.51%\n"
     ]
    }
   ],
   "source": [
    "## BAYES CLASSIFIER ERROR RATES 24 DIMENSIONS ##\n",
    "\n",
    "# 1- Get the total dataset training\n",
    "dataset_train = np.concatenate([dataset_default_for_training, dataset_nodefault_for_training])\n",
    "dataset_test = np.concatenate([dataset_default_for_testing, dataset_nodefault_for_testing])\n",
    "\n",
    "log_prob_train=default_payment_bayes_classifier.compute_predictions(dataset_train[:,1:-1])\n",
    "log_prob_test=default_payment_bayes_classifier.compute_predictions(dataset_test[:,1:-1])\n",
    "\n",
    "classesPred_train = log_prob_train.argmax(1)+1\n",
    "classesPred_test = log_prob_test.argmax(1)+1\n",
    "\n",
    "print \"Error Rate (training) %.2f%%\" % ((1-(classesPred_train==dataset_train[:,-1]).mean())*100.0)\n",
    "print \"Error Rate (test) %.2f%%\" % ((1-(classesPred_test==dataset_test[:,-1]).mean())*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
